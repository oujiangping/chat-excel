import gradio as gr
import pandas as pd
from llama_index.core.agent.workflow import AgentWorkflow, ToolCallResult, AgentOutput, ToolCall
from llama_index.core.memory import ChatMemoryBuffer
from llama_index.core.storage.chat_store import SimpleChatStore
from openpyxl import load_workbook

from agents.markdown_table_agent import MarkdownTableAgent
from export_tools import export_to_markdown
from openai_like_llm import OpenAILikeLLM, OPENAI_MODEL_NAME, OPENAI_API_BASE, OPENAI_API_KEY
from tools.table_tool import clear_sheets_db, set_sheets_db, get_excel_info_tool, \
    get_all_table_names, get_sheets_db, is_regular_table, test_run_sql_queries

# logging.basicConfig(level="DEBUG")


llm = OpenAILikeLLM(model=OPENAI_MODEL_NAME, api_base=OPENAI_API_BASE, api_key=OPENAI_API_KEY)

# æ˜¯å¦ä¸Šä¼ äº†æ–‡æ¡£
is_uploaded = False

chat_store = SimpleChatStore()
chat_memory = ChatMemoryBuffer.from_defaults(
    token_limit=8000,
    chat_store=chat_store,
    chat_store_key="user",
)


async def analyze_question(question):
    global is_uploaded
    if not is_uploaded:
        gr.Warning("è¯·å…ˆä¸Šä¼ Excelæ–‡ä»¶")
        return "è¯·å…ˆä¸Šä¼ Excelæ–‡ä»¶"
    markdown_agent = MarkdownTableAgent(llm)
    agent_workflow = AgentWorkflow(
        agents=[markdown_agent.get_agent()],
        root_agent=markdown_agent.get_agent_name(),
    )

    handler = agent_workflow.run(
        user_msg=question,
        memory=chat_memory
    )
    current_agent = None
    final_output = ""
    async for event in handler.stream_events():
        if (
                hasattr(event, "current_agent_name")
                and event.current_agent_name != current_agent
        ):
            current_agent = event.current_agent_name
            print(f"\n{'=' * 50}")
            print(f"ğŸ¤– Agent: {current_agent}")
            print(f"{'=' * 50}\n")
        elif isinstance(event, AgentOutput):
            if event.response.content:
                print("ğŸ“¤ Output:", event.response.content)
                final_output += event.response.content
            if event.tool_calls:
                print(
                    "ğŸ› ï¸  Planning to use tools:",
                    [call.tool_name for call in event.tool_calls],
                )
        elif isinstance(event, ToolCallResult):
            print(f"ğŸ”§ Tool Result ({event.tool_name}):")
            print(f"  Arguments: {event.tool_kwargs}")
            print(f"  Output: {event.tool_output}")
        elif isinstance(event, ToolCall):
            print(f"ğŸ”¨ Calling Tool: {event.tool_name}")
            print(f"  With arguments: {event.tool_kwargs}")
    return final_output


def load_excel(file):
    global is_uploaded
    # æ¸…é™¤ä¹‹å‰åŠ è½½çš„æ•°æ®
    # æ¸…é™¤ sheets_db
    # clear_sheets_db()
    # æ¸…é™¤åŠ¨æ€åˆ›å»ºçš„å…¨å±€å˜é‡
    table_names = list(get_all_table_names(get_sheets_db()))
    print(table_names)
    clear_sheets_db()

    # ä½¿ç”¨ openpyxl åŠ è½½ Excel æ–‡ä»¶
    wb = load_workbook(file.name)
    sheets_db = {}
    for sheet_name in wb.sheetnames:
        sheet = wb[sheet_name]
        merged_regions = []

        # æ”¶é›†æ‰€æœ‰åˆå¹¶åŒºåŸŸä¿¡æ¯ï¼ˆå·¦ä¸Šè§’åæ ‡å’ŒåŒºåŸŸèŒƒå›´ï¼‰
        for merged_range in sheet.merged_cells.ranges:
            min_row, max_row = merged_range.min_row, merged_range.max_row
            min_col, max_col = merged_range.min_col, merged_range.max_col
            top_left_value = sheet.cell(row=min_row, column=min_col).value
            merged_regions.append({
                'min_row': min_row,
                'max_row': max_row,
                'min_col': min_col,
                'max_col': max_col,
                'value': top_left_value
            })

        # æ£€æŸ¥æ˜¯å¦æ˜¯ç©ºè¡¨ï¼ˆè‡³å°‘éœ€è¦ä¸¤è¡Œæ•°æ®ï¼šæ ‡é¢˜è¡Œ+æ•°æ®è¡Œï¼‰
        if sheet.max_row <= 1:
            print(f"è¡¨ {sheet_name} æ•°æ®ä¸è¶³ï¼Œæ‹’ç»åŠ è½½ã€‚")
            continue

        # æ„å»ºå¤„ç†åçš„æ•°æ®çŸ©é˜µ
        data_matrix = []
        for row_idx in range(1, sheet.max_row + 1):
            row_data = []
            for col_idx in range(1, sheet.max_column + 1):
                cell_value = None
                # æ£€æŸ¥å½“å‰å•å…ƒæ ¼æ˜¯å¦å±äºæŸä¸ªåˆå¹¶åŒºåŸŸ
                for region in merged_regions:
                    if (region['min_row'] <= row_idx <= region['max_row'] and
                            region['min_col'] <= col_idx <= region['max_col']):
                        cell_value = region['value']
                        break  # æ‰¾åˆ°æ‰€å±åŒºåŸŸååœæ­¢æœç´¢
                if cell_value is None:
                    cell = sheet.cell(row=row_idx, column=col_idx)
                    cell_value = cell.value
                row_data.append(cell_value)
            data_matrix.append(row_data)

        # æå–æ ‡é¢˜å’Œæ•°æ®
        headers = data_matrix[0]
        data_rows = data_matrix[1:]

        # è½¬æ¢ä¸ºDataFrame
        df = pd.DataFrame(data_rows, columns=headers)

        markdown_text = df.to_markdown()
        print(markdown_text)

        if not is_regular_table(df):
            print(f"è¡¨ {sheet_name} ä¸æ˜¯æ­£è§„è¡¨æ ¼ï¼Œæ‹’ç»åŠ è½½ã€‚")
            gr.Warning(f"è¡¨ {sheet_name} ä¸æ˜¯æ­£è§„è¡¨æ ¼ï¼Œæ‹’ç»åŠ è½½ã€‚")
            continue
        else:
            sheets_db[sheet_name] = df
            print(f"æˆåŠŸåŠ è½½è¡¨ {sheet_name}ï¼Œè¡Œæ•°: {len(df)}")

        if not test_run_sql_queries(sheets_db):
            print(f"è¡¨ {sheet_name} æµ‹è¯•æ‰§è¡Œå¤±è´¥ï¼Œæ‹’ç»åŠ è½½ã€‚")
            gr.Warning(f"è¡¨ {sheet_name} æµ‹è¯•æ‰§è¡Œå¤±è´¥ï¼Œæ‹’ç»åŠ è½½ã€‚")
            return "è¡¨ {sheet_name} æµ‹è¯•æ‰§è¡Œå¤±è´¥ï¼Œæ‹’ç»åŠ è½½ã€‚"

    if not sheets_db:
        gr.Warning("æ²¡æœ‰æ‰¾åˆ°æ­£è§„è¡¨æ ¼ï¼Œæ‹’ç»åŠ è½½ã€‚")
        print("æ²¡æœ‰æ‰¾åˆ°æ­£è§„è¡¨æ ¼ï¼Œæ‹’ç»åŠ è½½ã€‚")
        return "æ²¡æœ‰æ‰¾åˆ°æ­£è§„è¡¨æ ¼ï¼Œæ‹’ç»åŠ è½½ã€‚"

    set_sheets_db(sheets_db)
    print(f"æˆåŠŸåŠ è½½ {len(sheets_db)} ä¸ªå·¥ä½œè¡¨: {', '.join(get_all_table_names(sheets_db))}")

    info_str = get_excel_info_tool()
    # æ‰“å° DataFrame çš„ä¿¡æ¯å’Œå‰å‡ è¡Œæ•°æ®
    print(info_str)
    is_uploaded = True

    return "Excel æ–‡ä»¶å·²æˆåŠŸåŠ è½½ã€‚"


with gr.Blocks() as excel_view:
    gr.Markdown("### Excel è¡¨æ ¼åˆ†æç³»ç»Ÿ")
    with gr.Row():
        with gr.Column():
            file_input = gr.File(label="é€‰æ‹© Excel æ–‡ä»¶")
            load_output = gr.Textbox(label="æ–‡ä»¶åŠ è½½ç»“æœ")
            question_input = gr.Textbox(label="è¯·è¾“å…¥é—®é¢˜", placeholder="è¾“å…¥ä½ çš„é—®é¢˜")
        with gr.Column():
            answer_output = gr.Markdown(label="åˆ†æç»“æœ")
            # Replace Spinner with a hidden textbox to simulate loading state
            loading_indicator = gr.Textbox(visible=False, value="Loading...")
            # æ·»åŠ  æ–‡ä»¶ å¯¼å‡ºæŒ‰é’®
            export_button = gr.Button("å¯¼å‡ºä¸º Markdown")
            export_button.click(
                fn=export_to_markdown,
                inputs=answer_output,
                outputs=gr.File(label="å¯¼å‡ºçš„ Markdown æ–‡ä»¶")
            )

    file_input.upload(load_excel, inputs=file_input, outputs=load_output)
    # Modify the submit call to add loading state control
    question_input.submit(
        fn=analyze_question,
        inputs=question_input,
        outputs=answer_output,
        queue=True
    )

if __name__ == "__main__":
    excel_view.launch()
