import gradio as gr
import pandas as pd
from llama_index.core.agent.workflow import FunctionAgent, AgentWorkflow, ToolCallResult, AgentOutput, ToolCall
from llama_index.core.memory import ChatMemoryBuffer
from llama_index.core.storage.chat_store import SimpleChatStore

from export_tools import export_to_markdown
from openai_like_llm import OpenAILikeLLM, OPENAI_MODEL_NAME, OPENAI_API_BASE, OPENAI_API_KEY
from tools.table_tool import run_sql_queries, clear_sheets_db, set_sheets_db, get_excel_info_tool, \
    get_all_table_names, get_sheets_db, get_global, is_regular_table
from tools.quickchart_tool import generate_bar_chart, generate_pie_chart

# logging.basicConfig(level="DEBUG")


llm = OpenAILikeLLM(model=OPENAI_MODEL_NAME, api_base=OPENAI_API_BASE, api_key=OPENAI_API_KEY)

# æ˜¯å¦ä¸Šä¼ äº†æ–‡æ¡£
is_uploaded = False

chat_store = SimpleChatStore()
chat_memory = ChatMemoryBuffer.from_defaults(
    token_limit=8000,
    chat_store=chat_store,
    chat_store_key="user",
)

# åˆ†æè¡¨æ ¼å¹²ä»€ä¹ˆçš„ä»£ç†
analyze_agent = FunctionAgent(
    name="analyze_agent",
    llm=llm,
    description="ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚",
    system_prompt=(
        """
        # è¡¨æ ¼åˆ†æåŠ©æ‰‹
        ## åŠŸèƒ½æè¿°
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¡¨æ ¼ç»Ÿè®¡åˆ†æå»ºè®®ç”ŸæˆåŠ©æ‰‹ï¼Œä¹Ÿæ˜¯æ•°æ®æ´å¯ŸåŠ©æ‰‹ï¼Œæ“…é•¿è¾“å‡ºå›¾æ–‡å¹¶èŒ‚çš„æ•°æ®æŠ¥å‘Šã€‚

        ## å·¥å…·ä½¿ç”¨è¯´æ˜
        # è¡¨æ ¼åˆ†æåŠ©æ‰‹
        ## åŠŸèƒ½æè¿°
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¡¨æ ¼ç»Ÿè®¡åˆ†æå»ºè®®ç”ŸæˆåŠ©æ‰‹ï¼Œä¹Ÿæ˜¯æ•°æ®æ´å¯ŸåŠ©æ‰‹ï¼Œæ“…é•¿è¾“å‡ºæ•°æ®æŠ¥å‘Šã€‚

        ## å·¥å…·ä½¿ç”¨è¯´æ˜
        -  get_excel_info_tool å·¥å…·è·å–pandasqlè¡¨æ ¼ä¿¡æ¯å’Œè¡¨åå¯ã€‚
        - generate_bar_chart å·¥å…·ç”¨äºç”Ÿæˆæ¡å½¢å›¾ï¼Œgenerate_pie_chart å·¥å…·ç”¨äºç”Ÿæˆé¥¼å›¾ï¼Œè¿”å›å›¾ç‰‡urlè¯·ä½ è‡ªå·±æ’å…¥æ­£æ–‡
        - å¯¹äºåˆ†æçš„æ•°æ®ä½ åº”è¯¥è€ƒè™‘è°ƒç”¨å›¾å½¢å·¥å…·å»ç”Ÿæˆå›¾ç‰‡å¹¶æ’å…¥æ­£æ–‡
        - run_sql_queries å·¥å…·ç”¨äºæ‰§è¡Œ SQL æŸ¥è¯¢ï¼Œè¿”å›æŸ¥è¯¢ç»“æœã€‚
        - è¯·ä½ ä¸€å®šè¦ä½¿ç”¨å›¾ç‰‡å·¥å…·å»ç”Ÿæˆå›¾ç‰‡ï¼Œä¸è¦è‡ªå·±ä¹±ç”Ÿæˆã€‚

        ## æ³¨æ„äº‹é¡¹
        - æ ¹æ®ç”¨æˆ·æå‡ºçš„é—®é¢˜è¿›è¡Œåˆ†æï¼Œç”Ÿæˆä¸¥æ ¼éµå®ˆ SQLite3 SQL è§„èŒƒçš„è¯­å¥ï¼ˆå¯ç”Ÿæˆå¤šæ¡ï¼‰ï¼Œé¿å…æ‰§è¡Œå‡ºé”™ã€‚
        - å•ä¸ª SQL æŸ¥è¯¢è¯­å¥çš„æœ€å¤§è¿”å›æ¡æ•°éœ€æ§åˆ¶åœ¨ 20 æ¡ä»¥å†…ï¼Œé˜²æ­¢å•ä¸ªæŸ¥è¯¢è¿”å›è¿‡å¤šæ•°æ®ã€‚
        - æ³¨æ„åªè¦ä½ åˆ†æå‡ºsqlè¯­å¥ï¼Œå°±å¯ä»¥ç›´æ¥æ‰§è¡Œsqlè¯­å¥ï¼Œä¸è¦å»é—®å®¢æˆ·ç«¯æ˜¯å¦éœ€è¦æ‰§è¡Œsqlè¯­å¥ã€‚
        - æ³¨æ„æ¯æ¬¡æ‰§è¡Œå‰ä½ éƒ½åº”è¯¥å…ˆè°ƒç”¨ `get_excel_info_tool` å·¥å…·è·å–è¡¨æ ¼ä¿¡æ¯ï¼Œå½“å‘ç”Ÿsqlé”™è¯¯æ—¶ä½ æ›´åŠ åº”è¯¥é‡æ–°è°ƒç”¨å·¥å…·è·å–è¡¨ä¿¡æ¯ï¼Œç„¶åå†æ ¹æ®è¡¨æ ¼ä¿¡æ¯ç”Ÿæˆsqlè¯­å¥ã€‚
        - ä½ åº”è¯¥æ­£ç¡®çš„è€ƒè™‘ä½¿ç”¨ä»€ä¹ˆå›¾å½¢åŒ–å·¥å…·å»ç”Ÿæˆå›¾ç‰‡ï¼ˆæ¡å½¢å›¾å¥½è¿˜æ˜¯é¥¼å›¾å¥½ï¼‰ï¼Œä¸è¦ä¸€ä¸ªåŠ²çš„åªä½¿ç”¨ä¸€ç§ã€‚
        - ç”±äºå­—æ®µåä¼šæœ‰ç©ºæ ¼ï¼Œæ‰€ä»¥ä½ éœ€è¦ä½¿ç”¨åå¼•å·åŒ…è£¹å­—æ®µåã€‚
        - æ‰€æœ‰çš„æ•°æ®å’Œå›¾è¡¨åº”è¯¥éƒ½æ˜¯é‡‡ç”¨å·¥å…·å¾—å‡ºï¼Œä¸èƒ½è‡ªå·±ä¹±ç¼–é€ ã€‚

        # è¾“å‡ºè¦æ±‚
        - ä»…å›ç­”ä¸è¡¨æ ¼ç›¸å…³çš„é—®é¢˜ï¼Œå¯¹äºè¡¨æ ¼æ— å…³çš„é—®é¢˜è¯·ç›´æ¥æ‹’ç»å›ç­”ã€‚
        - ä¾æ®è¡¨æ ¼ä¸­çš„æ•°æ®ï¼Œç”Ÿæˆæœ‰é’ˆå¯¹æ€§çš„ç»Ÿè®¡åˆ†æå»ºè®®ã€‚
        - é’ˆå¯¹æ¯ä¸ªæ•°æ®å¦‚æœèƒ½å¤Ÿç”Ÿæˆæ¡å½¢å›¾åº”è¯¥éƒ½å»è°ƒç”¨ä¸€æ¬¡å·¥å…·å»ç”Ÿæˆå›¾ç‰‡
        - è¾“å‡ºæŠ¥å‘Šé¢å‘æ™®é€šç”¨æˆ·ï¼Œsqlè¯­å¥åªæ˜¯ä½ çš„å·¥å…·åŠŸèƒ½ï¼Œç¦æ­¢æŠ¥å‘Šä¸­å‡ºç°sqlè¯­å¥
        - è¾“å‡ºæ•°æ®æŠ¥å‘Šç”¨Markdownæ ¼å¼ï¼Œè¦å›¾æ–‡å¹¶èŒ‚ã€‚
        - ä¸èƒ½æ— ä¸­ç”Ÿæœ‰ä¹±é€ æ•°æ®å’Œå›¾ç‰‡ã€‚
        """

    ),
    tools=[run_sql_queries, get_excel_info_tool, generate_bar_chart, generate_pie_chart],
    memory=chat_memory,
    verbose=True
)


async def analyze_question(question):
    global is_uploaded
    if not is_uploaded:
        gr.Warning("è¯·å…ˆä¸Šä¼ Excelæ–‡ä»¶")
        return "è¯·å…ˆä¸Šä¼ Excelæ–‡ä»¶"
    agent_workflow = AgentWorkflow(
        agents=[analyze_agent],
        root_agent=analyze_agent.name,
    )

    handler = agent_workflow.run(
        user_msg=question,
        memory=chat_memory
    )
    current_agent = None
    current_tool_calls = ""
    final_output = ""
    async for event in handler.stream_events():
        if (
                hasattr(event, "current_agent_name")
                and event.current_agent_name != current_agent
        ):
            current_agent = event.current_agent_name
            print(f"\n{'=' * 50}")
            print(f"ğŸ¤– Agent: {current_agent}")
            print(f"{'=' * 50}\n")
        elif isinstance(event, AgentOutput):
            if event.response.content:
                print("ğŸ“¤ Output:", event.response.content)
                final_output += event.response.content
            if event.tool_calls:
                print(
                    "ğŸ› ï¸  Planning to use tools:",
                    [call.tool_name for call in event.tool_calls],
                )
        elif isinstance(event, ToolCallResult):
            print(f"ğŸ”§ Tool Result ({event.tool_name}):")
            print(f"  Arguments: {event.tool_kwargs}")
            print(f"  Output: {event.tool_output}")
        elif isinstance(event, ToolCall):
            print(f"ğŸ”¨ Calling Tool: {event.tool_name}")
            print(f"  With arguments: {event.tool_kwargs}")
    return final_output


def load_excel(file):
    global is_uploaded
    # æ¸…é™¤ä¹‹å‰åŠ è½½çš„æ•°æ®
    # æ¸…é™¤ sheets_db
    # clear_sheets_db()
    # æ¸…é™¤åŠ¨æ€åˆ›å»ºçš„å…¨å±€å˜é‡
    table_names = list(get_all_table_names(get_sheets_db()))
    print(table_names)
    for name in table_names:
        if name in get_sheets_db():
            try:
                del get_global()[name]
            except KeyError:
                pass
    clear_sheets_db()

    # è¯»å– Excel æ–‡ä»¶
    sheets_db = pd.read_excel(file.name, sheet_name=None)
    set_sheets_db(sheets_db)
    print(f"æˆåŠŸåŠ è½½ {len(sheets_db)} ä¸ªå·¥ä½œè¡¨: {', '.join(get_all_table_names(sheets_db))}")

    # å°†å­—å…¸ä¸­çš„ DataFrame åˆ†é…å˜é‡åï¼ˆä¾‹å¦‚è¡¨åï¼‰
    for sheet_name, df in sheets_db.items():
        get_global()[sheet_name] = df  # åŠ¨æ€åˆ›å»ºå˜é‡ï¼ˆå¦‚ ordersã€customersï¼‰
        if not is_regular_table(df):
            print(f"è¡¨ {sheet_name} ä¸æ˜¯æ­£è§„è¡¨æ ¼ï¼Œæ‹’ç»åŠ è½½ã€‚")
            gr.Warning(f"è¡¨ {sheet_name} ä¸æ˜¯æ­£è§„è¡¨æ ¼ï¼Œæ‹’ç»åŠ è½½ã€‚")
            return f"è¡¨ {sheet_name} ä¸æ˜¯æ­£è§„è¡¨æ ¼ï¼Œæ‹’ç»åŠ è½½ã€‚"
    info_str = get_excel_info_tool()
    # æ‰“å° DataFrame çš„ä¿¡æ¯å’Œå‰å‡ è¡Œæ•°æ®
    print(info_str)
    is_uploaded = True
    return "Excel æ–‡ä»¶å·²æˆåŠŸåŠ è½½ã€‚"


with gr.Blocks() as excel_view:
    gr.Markdown("### Excel è¡¨æ ¼åˆ†æç³»ç»Ÿ")
    with gr.Row():
        with gr.Column():
            file_input = gr.File(label="é€‰æ‹© Excel æ–‡ä»¶")
            load_output = gr.Textbox(label="æ–‡ä»¶åŠ è½½ç»“æœ")
            question_input = gr.Textbox(label="è¯·è¾“å…¥é—®é¢˜", placeholder="è¾“å…¥ä½ çš„é—®é¢˜")
        with gr.Column():
            answer_output = gr.Markdown(label="åˆ†æç»“æœ")
            # Replace Spinner with a hidden textbox to simulate loading state
            loading_indicator = gr.Textbox(visible=False, value="Loading...")
            # æ·»åŠ  æ–‡ä»¶ å¯¼å‡ºæŒ‰é’®
            export_button = gr.Button("å¯¼å‡ºä¸º Markdown")
            export_button.click(
                fn=export_to_markdown,
                inputs=answer_output,
                outputs=gr.File(label="å¯¼å‡ºçš„ Markdown æ–‡ä»¶")
            )

    file_input.upload(load_excel, inputs=file_input, outputs=load_output)
    # Modify the submit call to add loading state control
    question_input.submit(
        fn=analyze_question,
        inputs=question_input,
        outputs=answer_output,
        queue=True
    )

if __name__ == "__main__":
    excel_view.launch()
